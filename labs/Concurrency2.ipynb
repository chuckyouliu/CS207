{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab\n",
    "\n",
    "Implement a URL fetcher using Beautiful Soup in the callback version. We will implement a similar one using coroutines on wednesday. \n",
    "\n",
    "The implimentation will extend the read_response method by parsing for URL's using `bs4` . Start by creating globals:\n",
    "```\n",
    "urls_todo = set(['/'])\n",
    "seen_urls = set(['/'])\n",
    "```\n",
    "\n",
    "then:\n",
    "\n",
    "```\n",
    "links = self.parse_links()#write this\n",
    "```\n",
    "(using self.response)\n",
    "\n",
    "Then use the set `difference` method  to add new links to `urls_todo` and recursively set up a `Fetcher` instance.\n",
    "\n",
    "Now update the `seen_urls` and `urls_todo` thus:\n",
    "```\n",
    "seen_urls.update(links)\n",
    "urls_todo.remove(self.url)\n",
    "if not urls_todo:\n",
    "    stopped = True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import socket\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selectors import DefaultSelector, EVENT_READ, EVENT_WRITE\n",
    "\n",
    "selector = DefaultSelector()\n",
    "class Fetcher:\n",
    "    def __init__(self, host, url, level=0):\n",
    "        self.response = b''  # Empty array of bytes.\n",
    "        self.host = host\n",
    "        self.url = url\n",
    "        self.sock = None\n",
    "        \n",
    "    # Method on Fetcher class.\n",
    "    def fetch(self):\n",
    "        self.sock = socket.socket()\n",
    "        self.sock.setblocking(False)\n",
    "        try:\n",
    "            self.sock.connect((self.host, 80))\n",
    "        except BlockingIOError:\n",
    "            pass\n",
    "\n",
    "        # Register next callback.\n",
    "        selector.register(self.sock.fileno(),\n",
    "                          EVENT_WRITE,\n",
    "                          self.connected)\n",
    "\n",
    "    def connected(self, key, mask):\n",
    "        print('connected!', flush=True)\n",
    "        selector.unregister(key.fd)\n",
    "        request = 'GET {} HTTP/1.0\\r\\nHost: {}\\r\\n\\r\\n'.format(self.url, self.host)\n",
    "        self.sock.send(request.encode('ascii'))\n",
    "\n",
    "        # Register the next callback.\n",
    "        selector.register(key.fd,\n",
    "                          EVENT_READ,\n",
    "                          self.read_response)\n",
    "        \n",
    "    def read_response(self, key, mask):\n",
    "        global stopped, urls_todo, seen_urls\n",
    "        \n",
    "        chunk = self.sock.recv(128)  # USUALLY 4k chunk size, here small\n",
    "        if chunk:\n",
    "            print(\"read chunk\", flush=True)\n",
    "            self.response += chunk\n",
    "        else:\n",
    "            print(\"all read\", flush=True)\n",
    "            selector.unregister(key.fd)  # Done reading.\n",
    "            links = self.parse_links()\n",
    "            links -= seen_urls\n",
    "            if len(links) > 0:\n",
    "                seen_urls.update(links)\n",
    "                for url in links:\n",
    "                    parsed_url = urlparse(url)\n",
    "                    hostname = parsed_url.hostname\n",
    "                    if hostname is None:\n",
    "                        hostname = self.host\n",
    "                    if parsed_url.path not in urls_todo:\n",
    "                        urls_todo.add(parsed_url.path)\n",
    "                        fetcher = Fetcher(hostname, parsed_url.path)\n",
    "                        fetcher.fetch()\n",
    "                urls_todo.remove(self.url)\n",
    "                if not urls_todo:\n",
    "                    stopped = True\n",
    "            #This line will stop the reading, otherwise it'll go on without stopping\n",
    "            else:\n",
    "                stopped = True\n",
    "            \n",
    "    def parse_links(self):\n",
    "        soup = BeautifulSoup(self.response, 'html.parser')\n",
    "        links = set()\n",
    "        for a in soup.find_all('a'):\n",
    "            links.add(a.get('href'))\n",
    "        return links\n",
    "                    \n",
    "stopped = False\n",
    "urls_todo = set(['/'])\n",
    "seen_urls = set(['/'])\n",
    "\n",
    "def loop():\n",
    "    while not stopped:\n",
    "        events = selector.select()\n",
    "        for event_key, event_mask in events:\n",
    "            callback = event_key.data\n",
    "            callback(event_key, event_mask)\n",
    "        #do fibonacci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connected!\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "all read\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "connected!\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "read chunk\n",
      "all read\n"
     ]
    }
   ],
   "source": [
    "fetcher = Fetcher('xkcd.com', '/')\n",
    "fetcher.fetch()\n",
    "loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
